---
title: "Куча предпосылок"
lang: russian
output:
  beamer_presentation:
    keep_tex: yes
    theme: CambridgeUS
  ioslides_presentation: default
---

# Предпосылки

Если:

1. Истинная зависимость имеет вид $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i+\varepsilon_i$
  * В матричном виде: $y=X\beta + \varepsilon$
2. С помощью МНК оценивается регрессия $y$ на константу, $x_i$, $z_i$
  * В матричном виде: $\hat{\beta}=(X'X)^{-1}X'y$
3. Наблюдений больше, чем оцениваемых коэффициентов $\beta$: $n>k$

# БСХС --- предположения на $\varepsilon_i$:
4. Строгая экзогенность: $E(\varepsilon_i | \text{ все регрессоры } )=0$
  * В матричном виде: $E(\varepsilon_i | X)=0$
5. Условная гомоскедастичность: $E(\varepsilon_i^2 | \text{ все регрессоры })=\sigma^2$
  * В матричном виде: $E(\varepsilon_i^2 | X)=\sigma^2$
6.  $Cov(\varepsilon_i,\varepsilon_j | X)=0$ при $i \neq j$

# БСХС --- предпосылки на регрессоры
7.  векторы отдельных наблюдений $(x_i,z_i,y_i)$ --- независимы и одинаково распределены
8.  с вероятностью 1 среди регрессоров нет линейно зависимых
* Синонимы в матричном виде: $rank(X)=k$ или $det(X'X)\neq 0$ или $(X'X)^{-1}$ существует


